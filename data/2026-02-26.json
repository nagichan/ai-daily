{
  "date": "2026-02-26",
  "aiNews": [
    {
      "title": "Salesforce CEO Marc Benioff: This isn’t our first SaaSpocalypse",
      "link": "https://techcrunch.com/2026/02/25/salesforce-ceo-marc-benioff-this-isnt-our-first-saaspocalypse/",
      "published": "Thu, 26 Feb 2026 01:59:12 +0000",
      "summary": "Salesforce reported a solid year-end earnings and then pulled out all the stops to ward off more talk of the death of its business to AI.",
      "source": "TechCrunch AI"
    },
    {
      "title": "Gushwork bets on AI search for customer leads — and early results are emerging",
      "link": "https://techcrunch.com/2026/02/25/gushwork-bets-on-ai-search-for-customer-leads-and-early-results-are-emerging/",
      "published": "Thu, 26 Feb 2026 00:00:00 +0000",
      "summary": "Gushwork has raised $9 million in a seed round led by SIG and Lightspeed. The startup has seen early customer traction from AI search tools like ChatGPT.",
      "source": "TechCrunch AI"
    },
    {
      "title": "Anthropic acquires computer-use AI startup Vercept after Meta poached one of its founders",
      "link": "https://techcrunch.com/2026/02/25/anthropic-acquires-vercept-ai-startup-agents-computer-use-founders-investors/",
      "published": "Wed, 25 Feb 2026 23:49:19 +0000",
      "summary": "Seattle-based Vercept developed complex agentic tools, including a computer-use agent that could complete tasks inside applications like a person with a laptop would.",
      "source": "TechCrunch AI"
    },
    {
      "title": "Nvidia has another record quarter amid record capex spends",
      "link": "https://techcrunch.com/2026/02/25/nvidia-earnings-record-capex-spend-ai/",
      "published": "Wed, 25 Feb 2026 23:04:42 +0000",
      "summary": "\"The demand for tokens in the world has gone completely exponential,\" Nvidia CEO Jensen Huang said about the company's earnings.",
      "source": "TechCrunch AI"
    },
    {
      "title": "Roundtables: Why 2026 Is the Year for Sodium-Ion Batteries",
      "link": "https://www.technologyreview.com/2026/02/25/1132873/roundtables-why-2026-is-the-year-for-sodium-ion-batteries/",
      "published": "Wed, 25 Feb 2026 21:15:27 +0000",
      "summary": "Listen to the session or watch below Sodium-based batteries could be a cheaper, safer alternative to lithium-ion, and the technology is finally making its way into cars—and energy storage arrays on th",
      "source": "MIT Tech Review"
    },
    {
      "title": "The White House wants AI companies to cover rate hikes. Most have already said they would.",
      "link": "https://techcrunch.com/2026/02/25/the-white-house-wants-ai-companies-to-cover-rate-hikes-most-have-already-said-they-would/",
      "published": "Wed, 25 Feb 2026 20:42:14 +0000",
      "summary": "Many hyperscalers have already made public commitments to cover electricity cost increases. ",
      "source": "TechCrunch AI"
    },
    {
      "title": "US cybersecurity agency CISA reportedly in dire shape amid Trump cuts and layoffs",
      "link": "https://techcrunch.com/2026/02/25/us-cybersecurity-agency-cisa-reportedly-in-dire-shape-amid-trump-cuts-and-layoffs/",
      "published": "Wed, 25 Feb 2026 20:26:57 +0000",
      "summary": "Under the first year of the Trump administration, the U.S. cyber agency CISA has faced cuts, layoffs, and furloughs, as bipartisan lawmakers and cybersecurity industry sources say the agency is unprep",
      "source": "TechCrunch AI"
    },
    {
      "title": "Welcome to the post-hype crypto market",
      "link": "https://techcrunch.com/video/welcome-to-the-post-hype-crypto-market/",
      "published": "Wed, 25 Feb 2026 20:22:11 +0000",
      "summary": "Crypto is creeping back into the startup conversation, but at ETHDenver last week, the buzz was as much about Washington as it was about tokens. Policy shifts are rippling through the market as Tether",
      "source": "TechCrunch AI"
    },
    {
      "title": "Alphabet-owned robotics software company Intrinsic joins Google",
      "link": "https://techcrunch.com/2026/02/25/alphabet-owned-robotics-software-company-intrinsic-joins-google/",
      "published": "Wed, 25 Feb 2026 20:00:00 +0000",
      "summary": "Nearly five years after graduating into an independent Alphabet company, Intrinsic is moving under Google's domain. ",
      "source": "TechCrunch AI"
    },
    {
      "title": "Snapchat announces ‘The Snappys,’ its first-ever creator awards show",
      "link": "https://techcrunch.com/2026/02/25/snapchat-announces-the-snappys-its-first-ever-creator-awards-show/",
      "published": "Wed, 25 Feb 2026 19:54:18 +0000",
      "summary": "Snapchat is the latest social media platform to launch awards for creators, joining TikTok and Instagram. ",
      "source": "TechCrunch AI"
    },
    {
      "title": "An accountant won a big jackpot on Kalshi by betting against DOGE",
      "link": "https://techcrunch.com/2026/02/25/an-accountant-won-a-big-jackpot-on-kalshi-by-betting-against-doge/",
      "published": "Wed, 25 Feb 2026 19:36:03 +0000",
      "summary": "A tax accountant saw Elon Musk fans bidding up a Kalshi prediction market and saw a sure bet to make easy money.",
      "source": "TechCrunch AI"
    },
    {
      "title": "Inside the story of the US defense contractor who leaked hacking tools to Russia",
      "link": "https://techcrunch.com/2026/02/25/inside-the-story-of-the-us-defense-contractor-who-leaked-hacking-tools-to-russia/",
      "published": "Wed, 25 Feb 2026 19:30:47 +0000",
      "summary": "The former boss of a U.S. hacking tools maker was jailed for selling highly sensitive software exploits to a Russian broker. This is how we first learned of his arrest, reported the story, and some of",
      "source": "TechCrunch AI"
    },
    {
      "title": "Samsung shows off new display tech that adds a privacy screen to apps and notifications",
      "link": "https://techcrunch.com/2026/02/25/samsung-shows-off-new-display-tech-that-adds-a-privacy-screen-to-apps-and-notifications/",
      "published": "Wed, 25 Feb 2026 19:23:58 +0000",
      "summary": "The new privacy tech uses different types of pixels to let you block certain apps and notifications from being viewed by others. ",
      "source": "TechCrunch AI"
    },
    {
      "title": "Wearable startup CUDIS launches a new health ring line with an AI-fueled ‘coach’",
      "link": "https://techcrunch.com/2026/02/25/wearable-startup-cudis-launches-a-new-health-ring-line-with-an-ai-fueled-coach/",
      "published": "Wed, 25 Feb 2026 19:10:04 +0000",
      "summary": "The wearable incentivizes healthy behavior with points that can be redeemed for health products. ",
      "source": "TechCrunch AI"
    },
    {
      "title": "Kalshi fined a MrBeast editor for insider trading on markets related to the YouTube star",
      "link": "https://techcrunch.com/2026/02/25/kalshi-fined-a-mrbeast-editor-for-insider-trading-on-markets-related-to-the-youtube-star/",
      "published": "Wed, 25 Feb 2026 19:08:04 +0000",
      "summary": "Kalshi fined the MrBeast editor, Artem Kaptur, over $20,000.",
      "source": "TechCrunch AI"
    },
    {
      "title": "The public opposition to AI infrastructure is heating up",
      "link": "https://techcrunch.com/2026/02/25/the-public-opposition-to-ai-infrastructure-is-heating-up/",
      "published": "Wed, 25 Feb 2026 19:03:34 +0000",
      "summary": "Public backlash over the data center boom is leading to a variety of draconian policies — including bans on new construction. ",
      "source": "TechCrunch AI"
    },
    {
      "title": "Waymo to begin testing in Chicago and Charlotte",
      "link": "https://techcrunch.com/2026/02/25/waymo-to-begin-testing-in-chicago-and-charlotte/",
      "published": "Wed, 25 Feb 2026 18:33:52 +0000",
      "summary": "Waymo this week will begin mapping and collecting data in Chicago and Charlotte. The move comes as Waymo announces it is currently operating its robotaxis fully autonomously in 10 US cities.  ",
      "source": "TechCrunch AI"
    },
    {
      "title": "Gemini can now automate some multi-step tasks on Android",
      "link": "https://techcrunch.com/2026/02/25/gemini-can-now-automate-some-multi-step-tasks-on-android/",
      "published": "Wed, 25 Feb 2026 18:00:00 +0000",
      "summary": "Gemini on Android will be able to automate tasks involving rideshare requests, or grocery or food delivery, says Google. ",
      "source": "TechCrunch AI"
    },
    {
      "title": "OpenAI COO says ads will be ‘an iterative process’",
      "link": "https://techcrunch.com/2026/02/25/openai-coo-says-ads-will-be-an-iterative-process/",
      "published": "Wed, 25 Feb 2026 17:37:37 +0000",
      "summary": "COO Brad Lightcap noted that ads can add to the product experience of users if they are done right. He urged to give OpenAI a few months to see how the company fares in rolling out the product.",
      "source": "TechCrunch AI"
    },
    {
      "title": "OpenClaw creator’s advice to AI builders is to be more playful and allow yourself time to improve",
      "link": "https://techcrunch.com/2026/02/25/openclaw-creators-advice-to-ai-builders-is-to-be-more-playful-and-allow-yourself-time-to-improve/",
      "published": "Wed, 25 Feb 2026 16:54:46 +0000",
      "summary": "Peter Steinberger talks about the creation of his viral AI agent OpenClaw and how being more \"playful\" makes for a better way to learn AI coding. ",
      "source": "TechCrunch AI"
    },
    {
      "title": "Have hard-won scaling lessons to share? Take the stage at TechCrunch Founder Summit 2026 ",
      "link": "https://techcrunch.com/2026/02/25/have-hard-won-scaling-lessons-to-share-take-the-stage-at-techcrunch-founder-summit/",
      "published": "Wed, 25 Feb 2026 16:00:00 +0000",
      "summary": "Apply to speak at TechCrunch Founder Summit 2026 by April 17 for a chance to lead a roundtable or breakout session for 1,000 founders and investors. If you’ve built, backed, or operated inside high-gr",
      "source": "TechCrunch AI"
    },
    {
      "title": "The Download: introducing the Crime issue",
      "link": "https://www.technologyreview.com/2026/02/25/1133653/the-download-introducing-the-crime-issue/",
      "published": "Wed, 25 Feb 2026 13:10:00 +0000",
      "summary": "This is today&#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. Introducing: the Crime issue Technology has long m",
      "source": "MIT Tech Review"
    },
    {
      "title": "Listen to Earth’s rumbling, secret soundtrack",
      "link": "https://www.technologyreview.com/2026/02/25/1132829/listen-earths-rumbling-secret-soundtrack/",
      "published": "Wed, 25 Feb 2026 11:00:00 +0000",
      "summary": "The boom of a calving glacier. The crackling rumble of a wildfire. The roar of a surging storm front. They’re the noises of the living Earth, music of this one particular sphere and clues to the true ",
      "source": "MIT Tech Review"
    },
    {
      "title": "3 things Juliet Beauchamp is into right now",
      "link": "https://www.technologyreview.com/2026/02/25/1132836/3-things-juliet-beauchamp/",
      "published": "Wed, 25 Feb 2026 11:00:00 +0000",
      "summary": "The only reality show that matters The Real Housewives of Salt Lake City is one of the best shows on television right now. Not one of the best reality TV shows, but one of the best TV shows, period. C",
      "source": "MIT Tech Review"
    },
    {
      "title": "Now is a good time for doing crime",
      "link": "https://www.technologyreview.com/2026/02/25/1132840/editors-letter-march-2026/",
      "published": "Wed, 25 Feb 2026 11:00:00 +0000",
      "summary": "Eons ago, in 2012, I had a weird experience. My iPhone suddenly shut down. When I restarted it, I found it was totally reset—clean, like a new device. This was the early days of iOS, so I wasn’t too c",
      "source": "MIT Tech Review"
    }
  ],
  "papers": [
    {
      "id": "http://arxiv.org/abs/2602.22039v1",
      "title": "TG-ASR: Translation-Guided Learning with Parallel Gated Cross Attention for Low-Resource Automatic Speech Recognition",
      "authors": [
        "Cheng-Yeh Yang",
        "Chien-Chun Wang",
        "Li-Wei Chen"
      ],
      "summary": "Low-resource automatic speech recognition (ASR) continues to pose significant challenges, primarily due to the limited availability of transcribed data for numerous languages. While a wealth of spoken content is accessible in television dramas and online videos, Taiwanese Hokkien exemplifies this issue, with transcriptions often being scarce and the majority of available subtitles provided only in Mandarin. To address this deficiency, we introduce TG-ASR for Taiwanese Hokkien drama speech recogn",
      "published": "2026-02-25T15:47:34Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.22039v1",
      "pdf": "http://arxiv.org/pdf/2602.22039v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.21900v1",
      "title": "EmoOmni: Bridging Emotional Understanding and Expression in Omni-Modal LLMs",
      "authors": [
        "Wenjie Tian",
        "Zhixian Zhao",
        "Jingbin Hu"
      ],
      "summary": "The evolution of Omni-Modal Large Language Models~(Omni-LLMs) has revolutionized human--computer interaction, enabling unified audio-visual perception and speech response. However, existing Omni-LLMs struggle with complex real-world scenarios, often leading to superficial understanding and contextually mismatched emotional responses. This issue is further intensified by Omni-LLM's Thinker-Talker architectures, which are implicitly connected through hidden states, leading to the loss of emotional",
      "published": "2026-02-25T13:30:27Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.21900v1",
      "pdf": "http://arxiv.org/pdf/2602.21900v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.21476v1",
      "title": "A Knowledge-Driven Approach to Music Segmentation, Music Source Separation and Cinematic Audio Source Separation",
      "authors": [
        "Chun-wei Ho",
        "Sabato Marco Siniscalchi",
        "Kai Li"
      ],
      "summary": "We propose a knowledge-driven, model-based approach to segmenting audio into single-category and mixed-category chunks with applications to source separation. \"Knowledge\" here denotes information associated with the data, such as music scores. \"Model\" here refers to tool that can be used for audio segmentation and recognition, such as hidden Markov models. In contrast to conventional learning that often relies on annotated data with given segment categories and their corresponding boundaries to ",
      "published": "2026-02-25T01:07:42Z",
      "category": "eess.AS",
      "link": "http://arxiv.org/abs/2602.21476v1",
      "pdf": "http://arxiv.org/pdf/2602.21476v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.21464v1",
      "title": "iMiGUE-Speech: A Spontaneous Speech Dataset for Affective Analysis",
      "authors": [
        "Sofoklis Kakouros",
        "Fang Kang",
        "Haoyu Chen"
      ],
      "summary": "This work presents iMiGUE-Speech, an extension of the iMiGUE dataset that provides a spontaneous affective corpus for studying emotional and affective states. The new release focuses on speech and enriches the original dataset with additional metadata, including speech transcripts, speaker-role separation between interviewer and interviewee, and word-level forced alignments. Unlike existing emotional speech datasets that rely on acted or laboratory-elicited emotions, iMiGUE-Speech captures spont",
      "published": "2026-02-25T00:38:19Z",
      "category": "eess.AS",
      "link": "http://arxiv.org/abs/2602.21464v1",
      "pdf": "http://arxiv.org/pdf/2602.21464v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.20967v1",
      "title": "Training-Free Intelligibility-Guided Observation Addition for Noisy ASR",
      "authors": [
        "Haoyang Li",
        "Changsong Liu",
        "Wei Rao"
      ],
      "summary": "Automatic speech recognition (ASR) degrades severely in noisy environments. Although speech enhancement (SE) front-ends effectively suppress background noise, they often introduce artifacts that harm recognition. Observation addition (OA) addressed this issue by fusing noisy and SE enhanced speech, improving recognition without modifying the parameters of the SE or ASR models. This paper proposes an intelligibility-guided OA method, where fusion weights are derived from intelligibility estimates",
      "published": "2026-02-24T14:46:54Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.20967v1",
      "pdf": "http://arxiv.org/pdf/2602.20967v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.20823v1",
      "title": "Geometric Analysis of Speech Representation Spaces: Topological Disentanglement and Confound Detection",
      "authors": [
        "Bipasha Kashyap",
        "Pubudu N. Pathirana"
      ],
      "summary": "Speech-based clinical tools are increasingly deployed in multilingual settings, yet whether pathological speech markers remain geometrically separable from accent variation remains unclear. Systems may misclassify healthy non-native speakers or miss pathology in multilingual patients. We propose a four-metric clustering framework to evaluate geometric disentanglement of emotional, linguistic, and pathological speech features across six corpora and eight dataset combinations. A consistent hierarc",
      "published": "2026-02-24T12:00:52Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.20823v1",
      "pdf": "http://arxiv.org/pdf/2602.20823v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.22029v1",
      "title": "MIDI-Informed Singing Accompaniment Generation in a Compositional Song Pipeline",
      "authors": [
        "Fang-Duo Tsai",
        "Yi-An Lai",
        "Fei-Yueh Chen"
      ],
      "summary": "Song generation aims to produce full songs with vocals and accompaniment from lyrics and text descriptions, yet end-to-end models remain data- and compute-intensive and provide limited editability. We advocate a compositional alternative that decomposes the task into melody composition, singing voice synthesis, and singing accompaniment generation. Central to our approach is MIDI-informed singing accompaniment generation (MIDI-SAG), which conditions accompaniment on the symbolic vocal-melody MID",
      "published": "2026-02-24T06:43:27Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.22029v1",
      "pdf": "http://arxiv.org/pdf/2602.22029v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.20592v1",
      "title": "Quantifying Dimensional Independence in Speech: An Information-Theoretic Framework for Disentangled Representation Learning",
      "authors": [
        "Bipasha Kashyap",
        "Björn W. Schuller",
        "Pubudu N. Pathirana"
      ],
      "summary": "Speech signals encode emotional, linguistic, and pathological information within a shared acoustic channel; however, disentanglement is typically assessed indirectly through downstream task performance. We introduce an information-theoretic framework to quantify cross-dimension statistical dependence in handcrafted acoustic features by integrating bounded neural mutual information (MI) estimation with non-parametric validation. Across six corpora, cross-dimension MI remains low, with tight estim",
      "published": "2026-02-24T06:33:03Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.20592v1",
      "pdf": "http://arxiv.org/pdf/2602.20592v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.20530v1",
      "title": "Memory-guided Prototypical Co-occurrence Learning for Mixed Emotion Recognition",
      "authors": [
        "Ming Li",
        "Yong-Jin Liu",
        "Fang Liu"
      ],
      "summary": "Emotion recognition from multi-modal physiological and behavioral signals plays a pivotal role in affective computing, yet most existing models remain constrained to the prediction of singular emotions in controlled laboratory settings. Real-world human emotional experiences, by contrast, are often characterized by the simultaneous presence of multiple affective states, spurring recent interest in mixed emotion recognition as an emotion distribution learning problem. Current approaches, however,",
      "published": "2026-02-24T04:11:25Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.20530v1",
      "pdf": "http://arxiv.org/pdf/2602.20530v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.19825v1",
      "title": "DTT-BSR: GAN-based DTTNet with RoPE Transformer Enhancement for Music Source Restoration",
      "authors": [
        "Shihong Tan",
        "Haoyu Wang",
        "Youran Ni"
      ],
      "summary": "Music source restoration (MSR) aims to recover unprocessed stems from mixed and mastered recordings. The challenge lies in both separating overlapping sources and reconstructing signals degraded by production effects such as compression and reverberation. We therefore propose DTT-BSR, a hybrid generative adversarial network (GAN) combining rotary positional embeddings (RoPE) transformer for long-term temporal modeling with dual-path band-split recurrent neural network (RNN) for multi-resolution ",
      "published": "2026-02-23T13:23:22Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.19825v1",
      "pdf": "http://arxiv.org/pdf/2602.19825v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.19574v1",
      "title": "CTC-TTS: LLM-based dual-streaming text-to-speech with CTC alignment",
      "authors": [
        "Hanwen Liu",
        "Saierdaer Yusuyin",
        "Hao Huang"
      ],
      "summary": "Large-language-model (LLM)-based text-to-speech (TTS) systems can generate natural speech, but most are not designed for low-latency dual-streaming synthesis. High-quality dual-streaming TTS depends on accurate text--speech alignment and well-designed training sequences that balance synthesis quality and latency. Prior work often relies on GMM-HMM based forced-alignment toolkits (e.g., MFA), which are pipeline-heavy and less flexible than neural aligners; fixed-ratio interleaving of text and spe",
      "published": "2026-02-23T07:44:14Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.19574v1",
      "pdf": "http://arxiv.org/pdf/2602.19574v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.21772v1",
      "title": "UniWhisper: Efficient Continual Multi-task Training for Robust Universal Audio Representation",
      "authors": [
        "Yuxuan Chen",
        "Peize He",
        "Haoyuan Xu"
      ],
      "summary": "A universal audio representation should capture fine-grained speech cues and high-level semantics for environmental sounds and music in a single encoder. Existing encoders often excel in one domain but degrade in others. We propose UniWhisper, an efficient continual multi-task training framework that casts heterogeneous audio tasks into a unified instruction and answer format. This enables standard next-token training without task-specific heads and losses. We train it on 38k hours of public aud",
      "published": "2026-02-25T10:47:20Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.21772v1",
      "pdf": "http://arxiv.org/pdf/2602.21772v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.21741v1",
      "title": "Robust Long-Form Bangla Speech Processing: Automatic Speech Recognition and Speaker Diarization",
      "authors": [
        "MD. Sagor Chowdhury",
        "Adiba Fairooz Chowdhury"
      ],
      "summary": "We describe our end-to-end system for Bengali long-form speech recognition (ASR) and speaker diarization submitted to the DL Sprint 4.0 competition on Kaggle. Bengali presents substantial challenges for both tasks: a large phoneme inventory, significant dialectal variation, frequent code-mixing with English, and a relative scarcity of large-scale labelled corpora. For ASR we achieve a best private Word Error Rate (WER) of 0.37738 and public WER of 0.36137, combining a BengaliAI fine-tuned Whispe",
      "published": "2026-02-25T09:52:32Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.21741v1",
      "pdf": "http://arxiv.org/pdf/2602.21741v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.21183v1",
      "title": "823-OLT @ BUET DL Sprint 4.0: Context-Aware Windowing for ASR and Fine-Tuned Speaker Diarization in Bengali Long Form Audio",
      "authors": [
        "Ratnajit Dhar",
        "Arpita Mallik"
      ],
      "summary": "Bengali, despite being one of the most widely spoken languages globally, remains underrepresented in long form speech technology, particularly in systems addressing transcription and speaker attribution. We present frameworks for long form Bengali speech intelligence that address automatic speech recognition using a Whisper Medium based model and speaker diarization using a finetuned segmentation model. The ASR pipeline incorporates vocal separation, voice activity detection, and a gap aware win",
      "published": "2026-02-24T18:34:14Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.21183v1",
      "pdf": "http://arxiv.org/pdf/2602.21183v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.20805v1",
      "title": "Assessing the Impact of Speaker Identity in Speech Spoofing Detection",
      "authors": [
        "Anh-Tuan Dao",
        "Driss Matrouf",
        "Nicholas Evans"
      ],
      "summary": "Spoofing detection systems are typically trained using diverse recordings from multiple speakers, often assuming that the resulting embeddings are independent of speaker identity. However, this assumption remains unverified. In this paper, we investigate the impact of speaker information on spoofing detection systems. We propose two approaches within our Speaker-Invariant Multi-Task framework, one that models speaker identity within the embeddings and another that removes it. SInMT integrates mu",
      "published": "2026-02-24T11:45:41Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.20805v1",
      "pdf": "http://arxiv.org/pdf/2602.20805v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.20744v1",
      "title": "Voices of the Mountains: Deep Learning-Based Vocal Error Detection System for Kurdish Maqams",
      "authors": [
        "Darvan Shvan Khairaldeen",
        "Hossein Hassani"
      ],
      "summary": "Maqam, a singing type, is a significant component of Kurdish music. A maqam singer receives training in a traditional face-to-face or through self-training. Automatic Singing Assessment (ASA) uses machine learning (ML) to provide the accuracy of singing styles and can help learners to improve their performance through error detection. Currently, the available ASA tools follow Western music rules. The musical composition requires all notes to stay within their expected pitch range from start to f",
      "published": "2026-02-24T10:17:16Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.20744v1",
      "pdf": "http://arxiv.org/pdf/2602.20744v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.20113v1",
      "title": "StyleStream: Real-Time Zero-Shot Voice Style Conversion",
      "authors": [
        "Yisi Liu",
        "Nicholas Lee",
        "Gopala Anumanchipalli"
      ],
      "summary": "Voice style conversion aims to transform an input utterance to match a target speaker's timbre, accent, and emotion, with a central challenge being the disentanglement of linguistic content from style. While prior work has explored this problem, conversion quality remains limited, and real-time voice style conversion has not been addressed. We propose StyleStream, the first streamable zero-shot voice style conversion system that achieves state-of-the-art performance. StyleStream consists of two ",
      "published": "2026-02-23T18:32:59Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.20113v1",
      "pdf": "http://arxiv.org/pdf/2602.20113v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.19976v1",
      "title": "SongEcho: Towards Cover Song Generation via Instance-Adaptive Element-wise Linear Modulation",
      "authors": [
        "Sifei Li",
        "Yang Li",
        "Zizhou Wang"
      ],
      "summary": "Cover songs constitute a vital aspect of musical culture, preserving the core melody of an original composition while reinterpreting it to infuse novel emotional depth and thematic emphasis. Although prior research has explored the reinterpretation of instrumental music through melody-conditioned text-to-music models, the task of cover song generation remains largely unaddressed. In this work, we reformulate our cover song generation as a conditional generation, which simultaneously generates ne",
      "published": "2026-02-23T15:42:38Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.19976v1",
      "pdf": "http://arxiv.org/pdf/2602.19976v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.19816v1",
      "title": "Depth-Structured Music Recurrence: Budgeted Recurrent Attention for Full-Piece Symbolic Music Modeling",
      "authors": [
        "Yungang Yi"
      ],
      "summary": "Long-context modeling is essential for symbolic music generation, since motif repetition and developmental variation can span thousands of musical events. However, practical composition and performance workflows frequently rely on resource-limited devices (e.g., electronic instruments and portable computers), making heavy memory and attention computation difficult to deploy. We introduce Depth-Structured Music Recurrence (DSMR), a recurrent long-context Transformer for full-piece symbolic music ",
      "published": "2026-02-23T13:13:41Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.19816v1",
      "pdf": "http://arxiv.org/pdf/2602.19816v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.19778v1",
      "title": "Enhancing Automatic Chord Recognition via Pseudo-Labeling and Knowledge Distillation",
      "authors": [
        "Nghia Phan",
        "Rong Jin",
        "Gang Liu"
      ],
      "summary": "Automatic Chord Recognition (ACR) is constrained by the scarcity of aligned chord labels, as well-aligned annotations are costly to acquire. At the same time, open-weight pre-trained models are currently more accessible than their proprietary training data. In this work, we present a two-stage training pipeline that leverages pre-trained models together with unlabeled audio. The proposed method decouples training into two stages. In the first stage, we use a pre-trained BTC model as a teacher to",
      "published": "2026-02-23T12:32:53Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.19778v1",
      "pdf": "http://arxiv.org/pdf/2602.19778v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.19674v2",
      "title": "Continuous Telemonitoring of Heart Failure using Personalised Speech Dynamics",
      "authors": [
        "Yue Pan",
        "Xingyao Wang",
        "Hanyue Zhang"
      ],
      "summary": "Remote monitoring of heart failure (HF) via speech signals provides a non-invasive and cost-effective solution for long-term patient management. However, substantial inter-individual heterogeneity in vocal characteristics often limits the accuracy of traditional cross-sectional classification models. To address this, we propose a Longitudinal Intra-Patient Tracking (LIPT) scheme designed to capture the trajectory of relative symptomatic changes within individuals. Central to this framework is a ",
      "published": "2026-02-23T10:19:17Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.19674v2",
      "pdf": "http://arxiv.org/pdf/2602.19674v2.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.19522v1",
      "title": "An LLM-Enabled Frequency-Aware Flow Diffusion Model for Natural-Language-Guided Power System Scenario Generation",
      "authors": [
        "Zhenghao Zhou",
        "Yiyan Li",
        "Fei Xie"
      ],
      "summary": "Diverse and controllable scenario generation (e.g., wind, solar, load, etc.) is critical for robust power system planning and operation. As AI-based scenario generation methods are becoming the mainstream, existing methods (e.g., Conditional Generative Adversarial Nets) mainly rely on a fixed-length numerical conditioning vector to control the generation results, facing challenges in user conveniency and generation flexibility. In this paper, a natural-language-guided scenario generation framewo",
      "published": "2026-02-23T05:22:38Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.19522v1",
      "pdf": "http://arxiv.org/pdf/2602.19522v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.19409v1",
      "title": "AuditoryHuM: Auditory Scene Label Generation and Clustering using Human-MLLM Collaboration",
      "authors": [
        "Henry Zhong",
        "Jörg M. Buchholz",
        "Julian Maclaren"
      ],
      "summary": "Manual annotation of audio datasets is labour intensive, and it is challenging to balance label granularity with acoustic separability. We introduce AuditoryHuM, a novel framework for the unsupervised discovery and clustering of auditory scene labels using a collaborative Human-Multimodal Large Language Model (MLLM) approach. By leveraging MLLMs (Gemma and Qwen) the framework generates contextually relevant labels for audio data. To ensure label quality and mitigate hallucinations, we employ zer",
      "published": "2026-02-23T01:02:03Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.19409v1",
      "pdf": "http://arxiv.org/pdf/2602.19409v1.pdf"
    },
    {
      "id": "http://arxiv.org/abs/2602.19395v1",
      "title": "DECAF: Dynamic Envelope Context-Aware Fusion for Speech-Envelope Reconstruction from EEG",
      "authors": [
        "Karan Thakkar",
        "Mounya Elhilali"
      ],
      "summary": "Reconstructing the speech audio envelope from scalp neural recordings (EEG) is a central task for decoding a listener's attentional focus in applications like neuro-steered hearing aids. Current methods for this reconstruction, however, face challenges with fidelity and noise. Prevailing approaches treat it as a static regression problem, processing each EEG window in isolation and ignoring the rich temporal structure inherent in continuous speech. This study introduces a new, dynamic framework ",
      "published": "2026-02-23T00:06:49Z",
      "category": "cs.SD",
      "link": "http://arxiv.org/abs/2602.19395v1",
      "pdf": "http://arxiv.org/pdf/2602.19395v1.pdf"
    }
  ],
  "blogs": [
    {
      "title": "MoE环游记：7、动态激活极简解",
      "link": "https://kexue.fm/archives/11626",
      "published": "Mon, 23 Feb 2026 10:31:00 +0800",
      "summary": "上一篇文章《MoE环游记：6、最优分配促均衡》中，我们通过求解如下最优分配问题来实现负载均衡\\begin{equation}\\max_{x_{i,j}\\in\\{0,1\\}} \\sum_{i,j}...",
      "source": "苏剑林的博客",
      "sourceUrl": "https://kexue.fm/"
    },
    {
      "title": "MoE环游记：6、最优分配促均衡",
      "link": "https://kexue.fm/archives/11619",
      "published": "Sun, 22 Feb 2026 10:15:00 +0800",
      "summary": "我们知道，负载均衡（Load Balance）是MoE架构中基本且关键的一环，直接影响模型的效率和性能。本系列已经有两篇文章介绍了两种实现负载均衡的主流思路，分别是《MoE环游记：2、不患寡而患...",
      "source": "苏剑林的博客",
      "sourceUrl": "https://kexue.fm/"
    }
  ]
}