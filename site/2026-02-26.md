# AI è¯­éŸ³æ—¥æŠ¥ - 2026å¹´2æœˆ26æ—¥æ˜ŸæœŸå››

> è‡ªåŠ¨ç”Ÿæˆ | æ•°æ®æ›´æ–°æ—¶é—´: 2026/2/26 16:25:34

---

## ğŸ“° AI å‰æ²¿èµ„è®¯

### 1. [Salesforce CEO Marc Benioff: This isnâ€™t our first SaaSpocalypse](https://techcrunch.com/2026/02/25/salesforce-ceo-marc-benioff-this-isnt-our-first-saaspocalypse/)
**æ¥æº**: TechCrunch AI
**æ‘˜è¦**: Salesforce reported a solid year-end earnings and then pulled out all the stops to ward off more talk of the death of its business to AI.

### 2. [Gushwork bets on äººå·¥æ™ºèƒ½ search ç”¨äº customer leads â€” å’Œ early results are emerging](https://techcrunch.com/2026/02/25/gushwork-bets-on-ai-search-for-customer-leads-and-early-results-are-emerging/)
**æ¥æº**: TechCrunch AI
**æ‘˜è¦**: Gushwork has raised $9 million in a seed round led by SIG and Lightspeed. The startup has seen early customer traction from AI search tools like ChatGPT.

### 3. [Anthropic acquires computer-use äººå·¥æ™ºèƒ½ startup Vercept after Meta poached one of its founders](https://techcrunch.com/2026/02/25/anthropic-acquires-vercept-ai-startup-agents-computer-use-founders-investors/)
**æ¥æº**: TechCrunch AI
**æ‘˜è¦**: Seattle-based Vercept developed complex agentic tools, including a computer-use agent that could complete tasks inside applications like a person with a laptop would.

### 4. [è‹±ä¼Ÿè¾¾ has another record quarter amid record capex spends](https://techcrunch.com/2026/02/25/nvidia-earnings-record-capex-spend-ai/)
**æ¥æº**: TechCrunch AI
**æ‘˜è¦**: "The demand for tokens in the world has gone completely exponential," Nvidia CEO Jensen Huang said about the company's earnings.

### 5. [Roundtables: Why 2026 Is  Year ç”¨äº Sodium-Ion Batteries](https://www.technologyreview.com/2026/02/25/1132873/roundtables-why-2026-is-the-year-for-sodium-ion-batteries/)
**æ¥æº**: MIT Tech Review
**æ‘˜è¦**: Listen to the session or watch below Sodium-based batteries could be a cheaper, safer alternative to lithium-ion, and the technology is finally making its way into carsâ€”and energy storage arrays on th

### 6. [ White House wants äººå·¥æ™ºèƒ½ companies to cover rate hikes. Most have already said they would.](https://techcrunch.com/2026/02/25/the-white-house-wants-ai-companies-to-cover-rate-hikes-most-have-already-said-they-would/)
**æ¥æº**: TechCrunch AI
**æ‘˜è¦**: Many hyperscalers have already made public commitments to cover electricity cost increases. 

### 7. [US cybersecurity agency CISA reportedly in dire shape amid Trump cuts å’Œ layoffs](https://techcrunch.com/2026/02/25/us-cybersecurity-agency-cisa-reportedly-in-dire-shape-amid-trump-cuts-and-layoffs/)
**æ¥æº**: TechCrunch AI
**æ‘˜è¦**: Under the first year of the Trump administration, the U.S. cyber agency CISA has faced cuts, layoffs, and furloughs, as bipartisan lawmakers and cybersecurity industry sources say the agency is unprep

### 8. [Welcome to  post-hype crypto market](https://techcrunch.com/video/welcome-to-the-post-hype-crypto-market/)
**æ¥æº**: TechCrunch AI
**æ‘˜è¦**: Crypto is creeping back into the startup conversation, but atÂ ETHDenverÂ last week, the buzz was as much about Washington as it was about tokens. Policy shifts are rippling through the market asÂ Tether

### 9. [Alphabet-owned robotics software company Intrinsic joins è°·æ­Œ](https://techcrunch.com/2026/02/25/alphabet-owned-robotics-software-company-intrinsic-joins-google/)
**æ¥æº**: TechCrunch AI
**æ‘˜è¦**: Nearly five years after graduating into an independent Alphabet company, Intrinsic is moving under Google's domain. 

### 10. [Snapchat announces â€˜ Snappys,â€™ its first-ever creator awards show](https://techcrunch.com/2026/02/25/snapchat-announces-the-snappys-its-first-ever-creator-awards-show/)
**æ¥æº**: TechCrunch AI
**æ‘˜è¦**: Snapchat is the latest social media platform to launch awards for creators, joining TikTok and Instagram. 

### 11. [ accountant won  big jackpot on Kalshi by betting against DOGE](https://techcrunch.com/2026/02/25/an-accountant-won-a-big-jackpot-on-kalshi-by-betting-against-doge/)
**æ¥æº**: TechCrunch AI
**æ‘˜è¦**: A tax accountant saw Elon Musk fans bidding up a Kalshi prediction market and saw a sure bet to make easy money.

### 12. [Inside  story of  US defense contractor who leaked hacking tools to Russia](https://techcrunch.com/2026/02/25/inside-the-story-of-the-us-defense-contractor-who-leaked-hacking-tools-to-russia/)
**æ¥æº**: TechCrunch AI
**æ‘˜è¦**: The former boss of a U.S. hacking tools maker was jailed for selling highly sensitive software exploits to a Russian broker. This is how we first learned of his arrest, reported the story, and some of

### 13. [ä¸‰æ˜Ÿ shows off æ–° display tech that adds  privacy screen to apps å’Œ notifications](https://techcrunch.com/2026/02/25/samsung-shows-off-new-display-tech-that-adds-a-privacy-screen-to-apps-and-notifications/)
**æ¥æº**: TechCrunch AI
**æ‘˜è¦**: The new privacy tech uses different types of pixels to let you block certain apps and notifications from being viewed by others. 

### 14. [Wearable startup CUDIS launches  æ–° health ring line å…·æœ‰  äººå·¥æ™ºèƒ½-fueled â€˜coachâ€™](https://techcrunch.com/2026/02/25/wearable-startup-cudis-launches-a-new-health-ring-line-with-an-ai-fueled-coach/)
**æ¥æº**: TechCrunch AI
**æ‘˜è¦**: The wearable incentivizes healthy behavior with points that can be redeemed for health products. 

### 15. [Kalshi fined  MrBeast editor ç”¨äº insider trading on markets related to  YouTube star](https://techcrunch.com/2026/02/25/kalshi-fined-a-mrbeast-editor-for-insider-trading-on-markets-related-to-the-youtube-star/)
**æ¥æº**: TechCrunch AI
**æ‘˜è¦**: Kalshi fined the MrBeast editor, Artem Kaptur, over $20,000.


---

## ğŸ¤ è¯­éŸ³å‰æ²¿è®ºæ–‡

*æ¥æº: arXiv eess.AS, cs.SD*

### 1. [TG-è‡ªåŠ¨è¯­éŸ³è¯†åˆ«: Translation-Guided å­¦ä¹  å…·æœ‰ Parallel Gated Cross æ³¨æ„åŠ›æœºåˆ¶ ç”¨äº Low-Resource Automatic è¯­éŸ³è¯†åˆ«](http://arxiv.org/abs/2602.22039v1)
**ä½œè€…**: Cheng-Yeh Yang, Chien-Chun Wang, Li-Wei Chen
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Low-resource automatic speech recognition (ASR) continues to pose significant challenges, primarily due to the limited availability of transcribed data for numerous languages. While a wealth of spoken content is accessible in television dramas and online videos, Taiwanese Hokkien exemplifies this is
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.22039v1.pdf)

### 2. [EmoOmni: Bridging Emotional Understanding å’Œ Expression in Omni-Modal LLMs](http://arxiv.org/abs/2602.21900v1)
**ä½œè€…**: Wenjie Tian, Zhixian Zhao, Jingbin Hu
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: The evolution of Omni-Modal Large Language Models~(Omni-LLMs) has revolutionized human--computer interaction, enabling unified audio-visual perception and speech response. However, existing Omni-LLMs struggle with complex real-world scenarios, often leading to superficial understanding and contextua
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.21900v1.pdf)

### 3. [ Knowledge-Driven æ–¹æ³• to éŸ³ä¹ åˆ†å‰², éŸ³ä¹ Source åˆ†ç¦» å’Œ Cinematic éŸ³é¢‘ Source åˆ†ç¦»](http://arxiv.org/abs/2602.21476v1)
**ä½œè€…**: Chun-wei Ho, Sabato Marco Siniscalchi, Kai Li
**åˆ†ç±»**: eess.AS
**æ‘˜è¦**: We propose a knowledge-driven, model-based approach to segmenting audio into single-category and mixed-category chunks with applications to source separation. "Knowledge" here denotes information associated with the data, such as music scores. "Model" here refers to tool that can be used for audio s
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.21476v1.pdf)

### 4. [iMiGUE-è¯­éŸ³:  Spontaneous è¯­éŸ³ æ•°æ®é›† ç”¨äº Affective Analysis](http://arxiv.org/abs/2602.21464v1)
**ä½œè€…**: Sofoklis Kakouros, Fang Kang, Haoyu Chen
**åˆ†ç±»**: eess.AS
**æ‘˜è¦**: This work presents iMiGUE-Speech, an extension of the iMiGUE dataset that provides a spontaneous affective corpus for studying emotional and affective states. The new release focuses on speech and enriches the original dataset with additional metadata, including speech transcripts, speaker-role sepa
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.21464v1.pdf)

### 5. [è®­ç»ƒ-Free Intelligibility-Guided Observation Addition ç”¨äº Noisy è‡ªåŠ¨è¯­éŸ³è¯†åˆ«](http://arxiv.org/abs/2602.20967v1)
**ä½œè€…**: Haoyang Li, Changsong Liu, Wei Rao
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Automatic speech recognition (ASR) degrades severely in noisy environments. Although speech enhancement (SE) front-ends effectively suppress background noise, they often introduce artifacts that harm recognition. Observation addition (OA) addressed this issue by fusing noisy and SE enhanced speech, 
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.20967v1.pdf)

### 6. [Geometric Analysis of è¯­éŸ³ è¡¨ç¤º Spaces: Topological Disentanglement å’Œ Confound æ£€æµ‹](http://arxiv.org/abs/2602.20823v1)
**ä½œè€…**: Bipasha Kashyap, Pubudu N. Pathirana
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Speech-based clinical tools are increasingly deployed in multilingual settings, yet whether pathological speech markers remain geometrically separable from accent variation remains unclear. Systems may misclassify healthy non-native speakers or miss pathology in multilingual patients. We propose a f
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.20823v1.pdf)

### 7. [MIDI-Informed Singing Accompaniment ç”Ÿæˆ in  Compositional Song Pipeline](http://arxiv.org/abs/2602.22029v1)
**ä½œè€…**: Fang-Duo Tsai, Yi-An Lai, Fei-Yueh Chen
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Song generation aims to produce full songs with vocals and accompaniment from lyrics and text descriptions, yet end-to-end models remain data- and compute-intensive and provide limited editability. We advocate a compositional alternative that decomposes the task into melody composition, singing voic
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.22029v1.pdf)

### 8. [Quantifying Dimensional Independence in è¯­éŸ³:  Information-Theoretic æ¡†æ¶ ç”¨äº Disentangled è¡¨ç¤º å­¦ä¹ ](http://arxiv.org/abs/2602.20592v1)
**ä½œè€…**: Bipasha Kashyap, BjÃ¶rn W. Schuller, Pubudu N. Pathirana
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Speech signals encode emotional, linguistic, and pathological information within a shared acoustic channel; however, disentanglement is typically assessed indirectly through downstream task performance. We introduce an information-theoretic framework to quantify cross-dimension statistical dependenc
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.20592v1.pdf)

### 9. [Memory-guided Prototypical Co-occurrence å­¦ä¹  ç”¨äº Mixed Emotion è¯†åˆ«](http://arxiv.org/abs/2602.20530v1)
**ä½œè€…**: Ming Li, Yong-Jin Liu, Fang Liu
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Emotion recognition from multi-modal physiological and behavioral signals plays a pivotal role in affective computing, yet most existing models remain constrained to the prediction of singular emotions in controlled laboratory settings. Real-world human emotional experiences, by contrast, are often 
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.20530v1.pdf)

### 10. [DTT-BSR: ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ-åŸºäº DTTNet å…·æœ‰ RoPE Transformeræ¨¡å‹ å¢å¼º ç”¨äº éŸ³ä¹ Source æ¢å¤](http://arxiv.org/abs/2602.19825v1)
**ä½œè€…**: Shihong Tan, Haoyu Wang, Youran Ni
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Music source restoration (MSR) aims to recover unprocessed stems from mixed and mastered recordings. The challenge lies in both separating overlapping sources and reconstructing signals degraded by production effects such as compression and reverberation. We therefore propose DTT-BSR, a hybrid gener
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.19825v1.pdf)

### 11. [CTC-è¯­éŸ³åˆæˆ: å¤§è¯­è¨€æ¨¡å‹-åŸºäº dual-streaming è¯­éŸ³åˆæˆ å…·æœ‰ CTC alignment](http://arxiv.org/abs/2602.19574v1)
**ä½œè€…**: Hanwen Liu, Saierdaer Yusuyin, Hao Huang
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Large-language-model (LLM)-based text-to-speech (TTS) systems can generate natural speech, but most are not designed for low-latency dual-streaming synthesis. High-quality dual-streaming TTS depends on accurate text--speech alignment and well-designed training sequences that balance synthesis qualit
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.19574v1.pdf)

### 12. [UniWhisper: Efficient Continual Multi-task è®­ç»ƒ ç”¨äº Robust Universal éŸ³é¢‘ è¡¨ç¤º](http://arxiv.org/abs/2602.21772v1)
**ä½œè€…**: Yuxuan Chen, Peize He, Haoyuan Xu
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: A universal audio representation should capture fine-grained speech cues and high-level semantics for environmental sounds and music in a single encoder. Existing encoders often excel in one domain but degrade in others. We propose UniWhisper, an efficient continual multi-task training framework tha
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.21772v1.pdf)

### 13. [Robust Long-Form Bangla è¯­éŸ³ Processing: Automatic è¯­éŸ³è¯†åˆ« å’Œ è¯´è¯äºº è¯´è¯äººåˆ†ç¦»](http://arxiv.org/abs/2602.21741v1)
**ä½œè€…**: MD. Sagor Chowdhury, Adiba Fairooz Chowdhury
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: We describe our end-to-end system for Bengali long-form speech recognition (ASR) and speaker diarization submitted to the DL Sprint 4.0 competition on Kaggle. Bengali presents substantial challenges for both tasks: a large phoneme inventory, significant dialectal variation, frequent code-mixing with
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.21741v1.pdf)

### 14. [823-OLT @ BUET DL Sprint 4.0: Context-Aware Windowing ç”¨äº è‡ªåŠ¨è¯­éŸ³è¯†åˆ« å’Œ Fine-Tuned è¯´è¯äºº è¯´è¯äººåˆ†ç¦» in Bengali Long Form éŸ³é¢‘](http://arxiv.org/abs/2602.21183v1)
**ä½œè€…**: Ratnajit Dhar, Arpita Mallik
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Bengali, despite being one of the most widely spoken languages globally, remains underrepresented in long form speech technology, particularly in systems addressing transcription and speaker attribution. We present frameworks for long form Bengali speech intelligence that address automatic speech re
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.21183v1.pdf)

### 15. [Assessing  Impact of è¯´è¯äºº Identity in è¯­éŸ³ Spoofing æ£€æµ‹](http://arxiv.org/abs/2602.20805v1)
**ä½œè€…**: Anh-Tuan Dao, Driss Matrouf, Nicholas Evans
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Spoofing detection systems are typically trained using diverse recordings from multiple speakers, often assuming that the resulting embeddings are independent of speaker identity. However, this assumption remains unverified. In this paper, we investigate the impact of speaker information on spoofing
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.20805v1.pdf)

### 16. [Voices of  Mountains: Deep å­¦ä¹ -åŸºäº Vocal Error æ£€æµ‹ ç³»ç»Ÿ ç”¨äº Kurdish Maqams](http://arxiv.org/abs/2602.20744v1)
**ä½œè€…**: Darvan Shvan Khairaldeen, Hossein Hassani
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Maqam, a singing type, is a significant component of Kurdish music. A maqam singer receives training in a traditional face-to-face or through self-training. Automatic Singing Assessment (ASA) uses machine learning (ML) to provide the accuracy of singing styles and can help learners to improve their 
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.20744v1.pdf)

### 17. [StyleStream: Real-Time é›¶æ ·æœ¬ å£°éŸ³ Style Conversion](http://arxiv.org/abs/2602.20113v1)
**ä½œè€…**: Yisi Liu, Nicholas Lee, Gopala Anumanchipalli
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Voice style conversion aims to transform an input utterance to match a target speaker's timbre, accent, and emotion, with a central challenge being the disentanglement of linguistic content from style. While prior work has explored this problem, conversion quality remains limited, and real-time voic
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.20113v1.pdf)

### 18. [SongEcho: Towards Cover Song ç”Ÿæˆ é€šè¿‡ Instance-Adaptive Element-wise Linear Modulation](http://arxiv.org/abs/2602.19976v1)
**ä½œè€…**: Sifei Li, Yang Li, Zizhou Wang
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Cover songs constitute a vital aspect of musical culture, preserving the core melody of an original composition while reinterpreting it to infuse novel emotional depth and thematic emphasis. Although prior research has explored the reinterpretation of instrumental music through melody-conditioned te
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.19976v1.pdf)

### 19. [Depth-Structured éŸ³ä¹ Recurrence: Budgeted Recurrent æ³¨æ„åŠ›æœºåˆ¶ ç”¨äº Full-Piece Symbolic éŸ³ä¹ Modeling](http://arxiv.org/abs/2602.19816v1)
**ä½œè€…**: Yungang Yi
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Long-context modeling is essential for symbolic music generation, since motif repetition and developmental variation can span thousands of musical events. However, practical composition and performance workflows frequently rely on resource-limited devices (e.g., electronic instruments and portable c
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.19816v1.pdf)

### 20. [Enhancing Automatic Chord è¯†åˆ« é€šè¿‡ Pseudo-Labeling å’Œ Knowledge è’¸é¦](http://arxiv.org/abs/2602.19778v1)
**ä½œè€…**: Nghia Phan, Rong Jin, Gang Liu
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Automatic Chord Recognition (ACR) is constrained by the scarcity of aligned chord labels, as well-aligned annotations are costly to acquire. At the same time, open-weight pre-trained models are currently more accessible than their proprietary training data. In this work, we present a two-stage train
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.19778v1.pdf)

### 21. [Continuous Telemonitoring of Heart Failure ä½¿ç”¨ Personalised è¯­éŸ³ Dynamics](http://arxiv.org/abs/2602.19674v2)
**ä½œè€…**: Yue Pan, Xingyao Wang, Hanyue Zhang
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Remote monitoring of heart failure (HF) via speech signals provides a non-invasive and cost-effective solution for long-term patient management. However, substantial inter-individual heterogeneity in vocal characteristics often limits the accuracy of traditional cross-sectional classification models
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.19674v2.pdf)

### 22. [ å¤§è¯­è¨€æ¨¡å‹-Enabled Frequency-Aware Flow æ‰©æ•£æ¨¡å‹ æ¨¡å‹ ç”¨äº Natural-Language-Guided Power ç³»ç»Ÿ Scenario ç”Ÿæˆ](http://arxiv.org/abs/2602.19522v1)
**ä½œè€…**: Zhenghao Zhou, Yiyan Li, Fei Xie
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Diverse and controllable scenario generation (e.g., wind, solar, load, etc.) is critical for robust power system planning and operation. As AI-based scenario generation methods are becoming the mainstream, existing methods (e.g., Conditional Generative Adversarial Nets) mainly rely on a fixed-length
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.19522v1.pdf)

### 23. [AuditoryHuM: Auditory Scene Label ç”Ÿæˆ å’Œ Clustering ä½¿ç”¨ Human-MLLM Collaboration](http://arxiv.org/abs/2602.19409v1)
**ä½œè€…**: Henry Zhong, JÃ¶rg M. Buchholz, Julian Maclaren
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Manual annotation of audio datasets is labour intensive, and it is challenging to balance label granularity with acoustic separability. We introduce AuditoryHuM, a novel framework for the unsupervised discovery and clustering of auditory scene labels using a collaborative Human-Multimodal Large Lang
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.19409v1.pdf)

### 24. [DECAF: Dynamic Envelope Context-Aware Fusion ç”¨äº è¯­éŸ³-Envelope é‡å»º æ¥è‡ª EEG](http://arxiv.org/abs/2602.19395v1)
**ä½œè€…**: Karan Thakkar, Mounya Elhilali
**åˆ†ç±»**: cs.SD
**æ‘˜è¦**: Reconstructing the speech audio envelope from scalp neural recordings (EEG) is a central task for decoding a listener's attentional focus in applications like neuro-steered hearing aids. Current methods for this reconstruction, however, face challenges with fidelity and noise. Prevailing approaches 
**PDF**: [ä¸‹è½½](http://arxiv.org/pdf/2602.19395v1.pdf)


---

## ğŸ‘¥ å…³æ³¨åšä¸»åŠ¨æ€

### 1. [MoEç¯æ¸¸è®°ï¼š7ã€åŠ¨æ€æ¿€æ´»æç®€è§£](https://kexue.fm/archives/11626)
**æ¥æº**: [è‹å‰‘æ—çš„åšå®¢](https://kexue.fm/)
**æ—¶é—´**: 2026/2/23

ä¸Šä¸€ç¯‡æ–‡ç« ã€ŠMoEç¯æ¸¸è®°ï¼š6ã€æœ€ä¼˜åˆ†é…ä¿ƒå‡è¡¡ã€‹ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æ±‚è§£å¦‚ä¸‹æœ€ä¼˜åˆ†é…é—®é¢˜æ¥å®ç°è´Ÿè½½å‡è¡¡\begin{equation}\max_{x_{i,j}\in\{0,1\}} \sum_{i,j}......

### 2. [MoEç¯æ¸¸è®°ï¼š6ã€æœ€ä¼˜åˆ†é…ä¿ƒå‡è¡¡](https://kexue.fm/archives/11619)
**æ¥æº**: [è‹å‰‘æ—çš„åšå®¢](https://kexue.fm/)
**æ—¶é—´**: 2026/2/22

æˆ‘ä»¬çŸ¥é“ï¼Œè´Ÿè½½å‡è¡¡ï¼ˆLoad Balanceï¼‰æ˜¯MoEæ¶æ„ä¸­åŸºæœ¬ä¸”å…³é”®çš„ä¸€ç¯ï¼Œç›´æ¥å½±å“æ¨¡å‹çš„æ•ˆç‡å’Œæ€§èƒ½ã€‚æœ¬ç³»åˆ—å·²ç»æœ‰ä¸¤ç¯‡æ–‡ç« ä»‹ç»äº†ä¸¤ç§å®ç°è´Ÿè½½å‡è¡¡çš„ä¸»æµæ€è·¯ï¼Œåˆ†åˆ«æ˜¯ã€ŠMoEç¯æ¸¸è®°ï¼š2ã€ä¸æ‚£å¯¡è€Œæ‚£......

---

*æœ¬æ—¥æŠ¥ç”± AI è‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*
