<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI è¯­éŸ³æ—¥æŠ¥ - 2026å¹´2æœˆ27æ—¥æ˜ŸæœŸäº”</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', sans-serif;
      line-height: 1.8;
      color: #333;
      background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
      min-height: 100vh;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
    }
    header {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      padding: 50px 30px;
      text-align: center;
      border-radius: 20px;
      margin-bottom: 30px;
      box-shadow: 0 10px 40px rgba(102, 126, 234, 0.3);
    }
    h1 { font-size: 2.2em; margin-bottom: 10px; }
    .subtitle { opacity: 0.9; font-size: 1em; }
    
    section {
      background: white;
      border-radius: 16px;
      padding: 30px;
      margin-bottom: 25px;
      box-shadow: 0 4px 20px rgba(0,0,0,0.08);
    }
    
    h2 {
      color: #333;
      font-size: 1.4em;
      margin-bottom: 20px;
      padding-bottom: 12px;
      border-bottom: 3px solid #667eea;
      display: inline-block;
    }
    
    .item {
      padding: 18px 0;
      border-bottom: 1px solid #eee;
    }
    .item:last-child { border-bottom: none; }
    
    .item h3 { 
      margin-bottom: 10px;
      font-size: 1.05em;
      font-weight: 600;
      line-height: 1.5;
    }
    .item h3 a {
      color: #333;
      text-decoration: none;
      transition: color 0.2s;
    }
    .item h3 a:hover { color: #667eea; }
    
    .meta {
      font-size: 0.85em;
      color: #888;
      margin-bottom: 10px;
    }
    
    .summary {
      color: #555;
      font-size: 0.95em;
      line-height: 1.7;
      background: #f8f9fa;
      padding: 12px 15px;
      border-radius: 8px;
      margin-top: 10px;
    }
    
    .tag {
      display: inline-block;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      padding: 3px 10px;
      border-radius: 20px;
      font-size: 0.75em;
      margin-right: 8px;
    }
    
    .pdf-link {
      display: inline-block;
      color: #667eea;
      font-size: 0.85em;
      margin-top: 8px;
      text-decoration: none;
      padding: 5px 12px;
      background: #f0f3ff;
      border-radius: 6px;
      transition: all 0.2s;
    }
    .pdf-link:hover {
      background: #667eea;
      color: white;
    }
    
    nav {
      background: white;
      border-radius: 12px;
      padding: 15px 25px;
      margin-bottom: 25px;
      box-shadow: 0 4px 20px rgba(0,0,0,0.08);
      text-align: center;
    }
    nav a {
      color: #667eea;
      text-decoration: none;
      margin: 0 15px;
      font-weight: 500;
      transition: color 0.2s;
    }
    nav a:hover { color: #764ba2; }
    
    /* ä¾§è¾¹æ æ—¥æœŸå¯¼èˆª */
    .sidebar {
      position: fixed;
      right: 20px;
      top: 50%;
      transform: translateY(-50%);
      background: white;
      border-radius: 12px;
      padding: 15px;
      box-shadow: 0 4px 20px rgba(0,0,0,0.1);
      max-height: 60vh;
      overflow-y: auto;
      z-index: 100;
      min-width: 140px;
    }
    .sidebar h4 {
      color: #667eea;
      font-size: 0.9em;
      margin-bottom: 10px;
      padding-bottom: 8px;
      border-bottom: 2px solid #eee;
    }
    .sidebar a {
      display: block;
      color: #666;
      text-decoration: none;
      padding: 6px 10px;
      border-radius: 6px;
      font-size: 0.85em;
      margin: 3px 0;
      transition: all 0.2s;
    }
    .sidebar a:hover {
      background: #f0f3ff;
      color: #667eea;
    }
    .sidebar a.active {
      background: #667eea;
      color: white;
    }
    .sidebar a.today {
      color: #667eea;
      font-weight: 600;
    }
    
    @media (max-width: 1200px) {
      .sidebar { display: none; }
    }
    
    footer {
      text-align: center;
      color: #888;
      font-size: 0.85em;
      padding: 30px;
    }
    
    .count {
      background: #667eea;
      color: white;
      padding: 2px 8px;
      border-radius: 10px;
      font-size: 0.8em;
      margin-left: 8px;
    }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <h1>ğŸ¤ AI è¯­éŸ³æ—¥æŠ¥</h1>
      <p class="subtitle">2026å¹´2æœˆ27æ—¥æ˜ŸæœŸäº”</p>
    </header>
    
    <nav>
      <a href="#ai-news">ğŸ“° AIèµ„è®¯</a>
      <a href="#papers">ğŸ¤ è¯­éŸ³è®ºæ–‡</a>
      <a href="#blogs">ğŸ‘¥ åšä¸»åŠ¨æ€</a>
      <a href="index.html">ğŸ“… å†å²</a>
    </nav>
    
    <section id="ai-news">
      <h2>ğŸ“° AI å‰æ²¿èµ„è®¯ <span class="count">0</span></h2>
      <p style="color:#888;text-align:center;padding:20px;">æš‚æ— æ›´æ–°</p>
    </section>
    
    <section id="papers">
      <h2>ğŸ¤ è¯­éŸ³å‰æ²¿è®ºæ–‡ <span class="count">6</span></h2>
      <p style="color:#888;font-size:0.9em;margin-bottom:15px;">æ¥æº: arXiv eess.AS, cs.SDï¼ˆæ ‡é¢˜ä¿ç•™è‹±æ–‡åŸæ–‡ï¼‰</p>
      
        <div class="item">
          <h3><a href="http://arxiv.org/abs/2602.22039v1" target="_blank">TG-ASR: Translation-Guided Learning with Parallel Gated Cross Attention for Low-Resource Automatic Speech Recognition</a></h3>
          <div class="meta">
            <span class="tag">cs.SD</span>
            ğŸ‘¤ Cheng-Yeh Yang, Chien-Chun Wang, Li-Wei Chen
          </div>
          <div class="summary">Low-resource automatic speech recognition (ASR) continues to pose significant challenges, primarily due to the limited availability of transcribed data for numerous languages.</div>
          <a href="http://arxiv.org/pdf/2602.22039v1.pdf" target="_blank" class="pdf-link">ğŸ“„ ä¸‹è½½ PDF</a>
        </div>
      
        <div class="item">
          <h3><a href="http://arxiv.org/abs/2602.21900v1" target="_blank">EmoOmni: Bridging Emotional Understanding and Expression in Omni-Modal LLMs</a></h3>
          <div class="meta">
            <span class="tag">cs.SD</span>
            ğŸ‘¤ Wenjie Tian, Zhixian Zhao, Jingbin Hu
          </div>
          <div class="summary">The evolution of Omni-Modal Large Language Models~(Omni-LLMs) has revolutionized human--computer interaction, enabling unified audio-visual perception and speech response.</div>
          <a href="http://arxiv.org/pdf/2602.21900v1.pdf" target="_blank" class="pdf-link">ğŸ“„ ä¸‹è½½ PDF</a>
        </div>
      
        <div class="item">
          <h3><a href="http://arxiv.org/abs/2602.21476v1" target="_blank">A Knowledge-Driven Approach to Music Segmentation, Music Source Separation and Cinematic Audio Source Separation</a></h3>
          <div class="meta">
            <span class="tag">eess.AS</span>
            ğŸ‘¤ Chun-wei Ho, Sabato Marco Siniscalchi, Kai Li
          </div>
          <div class="summary">We propose a knowledge-driven, model-based approach to segmenting audio into single-category and mixed-category chunks with applications to source separation.</div>
          <a href="http://arxiv.org/pdf/2602.21476v1.pdf" target="_blank" class="pdf-link">ğŸ“„ ä¸‹è½½ PDF</a>
        </div>
      
        <div class="item">
          <h3><a href="http://arxiv.org/abs/2602.21464v1" target="_blank">iMiGUE-Speech: A Spontaneous Speech Dataset for Affective Analysis</a></h3>
          <div class="meta">
            <span class="tag">eess.AS</span>
            ğŸ‘¤ Sofoklis Kakouros, Fang Kang, Haoyu Chen
          </div>
          <div class="summary">This work presents iMiGUE-Speech, an extension of the iMiGUE dataset that provides a spontaneous affective corpus for studying emotional and affective states.</div>
          <a href="http://arxiv.org/pdf/2602.21464v1.pdf" target="_blank" class="pdf-link">ğŸ“„ ä¸‹è½½ PDF</a>
        </div>
      
        <div class="item">
          <h3><a href="http://arxiv.org/abs/2602.21772v1" target="_blank">UniWhisper: Efficient Continual Multi-task Training for Robust Universal Audio Representation</a></h3>
          <div class="meta">
            <span class="tag">cs.SD</span>
            ğŸ‘¤ Yuxuan Chen, Peize He, Haoyuan Xu
          </div>
          <div class="summary">A universal audio representation should capture fine-grained speech cues and high-level semantics for environmental sounds and music in a single encoder.</div>
          <a href="http://arxiv.org/pdf/2602.21772v1.pdf" target="_blank" class="pdf-link">ğŸ“„ ä¸‹è½½ PDF</a>
        </div>
      
        <div class="item">
          <h3><a href="http://arxiv.org/abs/2602.21741v1" target="_blank">Robust Long-Form Bangla Speech Processing: Automatic Speech Recognition and Speaker Diarization</a></h3>
          <div class="meta">
            <span class="tag">cs.SD</span>
            ğŸ‘¤ MD. Sagor Chowdhury, Adiba Fairooz Chowdhury
          </div>
          <div class="summary">We describe our end-to-end system for Bengali long-form speech recognition (ASR) and speaker diarization submitted to the DL Sprint 4.0 competition on Kaggle.</div>
          <a href="http://arxiv.org/pdf/2602.21741v1.pdf" target="_blank" class="pdf-link">ğŸ“„ ä¸‹è½½ PDF</a>
        </div>
      
    </section>
    
    <section id="blogs">
      <h2>ğŸ‘¥ å…³æ³¨åšä¸»åŠ¨æ€ <span class="count">0</span></h2>
      <p style="color:#888;text-align:center;padding:20px;">æš‚æ— æ›´æ–°</p>
    </section>
    
    <footer>
      <p>ğŸ¤– æœ¬æ—¥æŠ¥ç”± AI è‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ</p>
      <p style="margin-top:8px;color:#aaa;">æ›´æ–°æ—¶é—´: 2026/2/27 09:45:48</p>
    </footer>
  </div>
  
  <!-- ä¾§è¾¹æ æ—¥æœŸå¯¼èˆª -->
  
  <div class="sidebar">
    <h4>ğŸ“… å†å²æ—¥æŠ¥</h4>
    
      <a href="2026-02-27.html" class="active">2026å¹´2æœˆ27æ—¥æ˜ŸæœŸäº”</a>
    
      <a href="2026-02-26.html" class="">2026å¹´2æœˆ26æ—¥æ˜ŸæœŸå››</a>
    
  </div>
  
</body>
</html>